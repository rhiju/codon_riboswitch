{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0_Simple_1D_fit.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOZRObL+G4fC57J3hedUusw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rhiju/codon_riboswitch/blob/master/0_Simple_1D_fit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuLXaO3q2_Bo",
        "outputId": "7e5cd45f-c840-4790-972e-c2452a7530ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "\n",
        "def rmse(y, y_hat):\n",
        "    \"\"\"Compute root mean squared error\"\"\"\n",
        "    return torch.sqrt(torch.mean((y - y_hat).pow(2)))\n",
        "\n",
        "def forward(x, e):\n",
        "    \"\"\"Forward pass for our fuction\"\"\"\n",
        "    return x.pow(e.repeat(x.size(0)))\n",
        "\n",
        "# Let's define some settings\n",
        "n = 1000 # number of examples\n",
        "learning_rate = 5e-7\n",
        "\n",
        "# Model definition\n",
        "x = Variable(torch.rand(n) * 10, requires_grad=False)\n",
        "y = forward(x, exp)\n",
        "\n",
        "# Model parameters\n",
        "exp = Variable(torch.FloatTensor([2.0]), requires_grad=False)\n",
        "exp_hat = Variable(torch.FloatTensor([4]), requires_grad=True)\n",
        "\n",
        "# Optimizer (NEW)\n",
        "opt = torch.optim.SGD([exp_hat], lr=learning_rate, momentum=0.9)\n",
        "\n",
        "loss_history = []\n",
        "exp_history = []\n",
        "\n",
        "# Training loop\n",
        "for i in range(0, 2000):\n",
        "    opt.zero_grad()\n",
        "    \n",
        "    # Compute current estimate\n",
        "    y_hat = forward(x, exp_hat)\n",
        "    \n",
        "    # Calculate loss function\n",
        "    loss = rmse(y, y_hat)\n",
        "    \n",
        "    # Do some recordings for plots\n",
        "    loss_history.append(loss.item())\n",
        "    exp_history.append(y_hat.data[0])\n",
        "    \n",
        "    # Update model parameters\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    if (i%100 == 0):\n",
        "      print(\"Iteration %d\" % i)\n",
        "      print(\"loss = %s\" % loss.item())\n",
        "      print(\"exp = %s\" % exp_hat.data[0])\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 0\n",
            "loss = 3116.94189453125\n",
            "exp = tensor(3.9965)\n",
            "Iteration 100\n",
            "loss = 291.3119812011719\n",
            "exp = tensor(2.9600)\n",
            "Iteration 200\n",
            "loss = 140.8204345703125\n",
            "exp = tensor(2.6829)\n",
            "Iteration 300\n",
            "loss = 85.20350646972656\n",
            "exp = tensor(2.5146)\n",
            "Iteration 400\n",
            "loss = 55.808868408203125\n",
            "exp = tensor(2.3925)\n",
            "Iteration 500\n",
            "loss = 37.53822326660156\n",
            "exp = tensor(2.2963)\n",
            "Iteration 600\n",
            "loss = 25.050519943237305\n",
            "exp = tensor(2.2168)\n",
            "Iteration 700\n",
            "loss = 15.961816787719727\n",
            "exp = tensor(2.1491)\n",
            "Iteration 800\n",
            "loss = 9.04394817352295\n",
            "exp = tensor(2.0900)\n",
            "Iteration 900\n",
            "loss = 3.598360538482666\n",
            "exp = tensor(2.0377)\n",
            "Iteration 1000\n",
            "loss = 0.05870901793241501\n",
            "exp = tensor(2.0007)\n",
            "Iteration 1100\n",
            "loss = 0.0030424317810684443\n",
            "exp = tensor(2.0000)\n",
            "Iteration 1200\n",
            "loss = 0.0010249537881463766\n",
            "exp = tensor(2.0000)\n",
            "Iteration 1300\n",
            "loss = 0.003905585268512368\n",
            "exp = tensor(2.0000)\n",
            "Iteration 1400\n",
            "loss = 0.0003344874130561948\n",
            "exp = tensor(2.0000)\n",
            "Iteration 1500\n",
            "loss = 0.003721858374774456\n",
            "exp = tensor(2.0000)\n",
            "Iteration 1600\n",
            "loss = 0.0017044887645170093\n",
            "exp = tensor(2.0000)\n",
            "Iteration 1700\n",
            "loss = 0.0020929838065057993\n",
            "exp = tensor(2.0000)\n",
            "Iteration 1800\n",
            "loss = 0.0030424317810684443\n",
            "exp = tensor(2.0000)\n",
            "Iteration 1900\n",
            "loss = 0.0010249537881463766\n",
            "exp = tensor(2.0000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0Rgg4PB3hiI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}